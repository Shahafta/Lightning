{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R-squared on test data: 0.180755\n",
      "Selected features: ['Latitude' 'Longitude' 'Salinity' 'Temperature' 'Acidity' 'Alkalinity'\n",
      " 'Carbon' 'tecUHR' 'sunspot' 'Alk/Sal' 'Precipitation' 'TSI' 'CAPE']\n",
      "RMSE on train set: 88258.585256\n",
      "RMSE on test set: 86240.455613\n",
      "STD on test set: 85220.66\n"
     ]
    }
   ],
   "source": [
    "#LinearRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "max_accuracy = 0\n",
    "best_features = []\n",
    "\n",
    "df = pd.read_csv('../relevant csvs/POWER VECTOR.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "for i in range(1,14):\n",
    "\n",
    "    # Define the target variable and the features you want to use for prediction\n",
    "    target = 'Power (J)'\n",
    "    \n",
    "    features = ['Latitude','Longitude','Salinity', 'Temperature', 'Acidity','Alkalinity', 'Carbon','tecUHR','sunspot','Alk/Sal','Precipitation','TSI','CAPE']\n",
    "    #features = ['Longitude','Salinity', 'Temperature', 'Acidity', 'Alkalinity', 'Carbon','Alk/Sal','Precipitation']\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], np.log(df[target]), test_size=0.2, random_state=42)\n",
    "\n",
    "    # Use SelectKBest to select the top k features based on f_regression score\n",
    "    selector = SelectKBest(f_regression, k=i)\n",
    "    X_train = selector.fit_transform(X_train, y_train)\n",
    "    X_test = selector.transform(X_test)\n",
    "\n",
    "    # Create a linear regression model\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model's performance using R-squared metric\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    if(r2>max_accuracy):\n",
    "            max_accuracy=r2\n",
    "            best_features = np.array(features)[selector.get_support()]\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            rmse_train = np.sqrt(mean_squared_error(np.exp(y_train), np.exp(y_pred_train)))\n",
    "            rmse_test = np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred)))\n",
    "            std_y_test = np.exp(y_test).std()\n",
    "    #print(\"R-squared on test data: {:.6f}\".format(r2))\n",
    "    #print(\"Selected features: {}\".format(np.array(features)[selector.get_support()]))\n",
    "print(\"Best R-squared on test data: {:.6f}\".format(max_accuracy))\n",
    "print(\"Selected features: {}\".format(best_features))\n",
    "\n",
    "# Print the RMSE values\n",
    "print(\"RMSE on train set: {:.6f}\".format(rmse_train))\n",
    "print(\"RMSE on test set: {:.6f}\".format(rmse_test))\n",
    "print(\"STD on test set: {:.2f}\".format(std_y_test))\n",
    "#0.116710\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R-squared on test data: 0.323026\n",
      "Selected features: ['Latitude' 'Longitude' 'Salinity' 'Temperature' 'Acidity' 'Alkalinity'\n",
      " 'Carbon' 'tecUHR' 'sunspot' 'Alk/Sal' 'Precipitation' 'TSI' 'CAPE']\n",
      "RMSE on train set: 85619.967404\n",
      "RMSE on test set: 85772.603451\n",
      "STD on test set: 85220.66\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "max_accuracy = 0\n",
    "best_features = []\n",
    "\n",
    "df = pd.read_csv('../relevant csvs/power vector.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "for i in range(1,14):\n",
    "    # Load the data into a Pandas dataframe\n",
    "\n",
    "\n",
    "    # Define the target variable and the features you want to use for prediction\n",
    "    target = 'Power (J)'\n",
    "    features = ['Latitude','Longitude','Salinity', 'Temperature', 'Acidity','Alkalinity', 'Carbon','tecUHR','sunspot','Alk/Sal','Precipitation','TSI','CAPE']\n",
    "    #features = ['Longitude','Salinity', 'Temperature', 'Acidity', 'Alkalinity', 'Carbon','Alk/Sal','Precipitation']\n",
    "\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], np.log(df[target]), test_size=0.2, random_state=42)\n",
    "\n",
    "    # Use SelectKBest to select the top k features based on f_regression score\n",
    "    selector = SelectKBest(f_regression, k=i)\n",
    "    X_train = selector.fit_transform(X_train, y_train)\n",
    "    X_test = selector.transform(X_test)\n",
    "\n",
    "    \n",
    "    for j in range(1,i+1):\n",
    "        #print(\"Max depth: {:.0f}\".format(j))\n",
    "        # Create a linear regression model\n",
    "        #model = GradientBoostingRegressor(n_estimators=100, max_depth=3)\n",
    "        model = DecisionTreeRegressor(max_depth=j)\n",
    "\n",
    "        # Fit the model to the training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model's performance using R-squared metric\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        if(r2>max_accuracy):\n",
    "            max_accuracy=r2\n",
    "            best_features = np.array(features)[selector.get_support()]\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            rmse_train = np.sqrt(mean_squared_error(np.exp(y_train), np.exp(y_pred_train)))\n",
    "            rmse_test = np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred)))\n",
    "            std_y_test = np.exp(y_test).std()\n",
    "        #print(\"R-squared on test data: {:.6f}\".format(r2))\n",
    "        #print(\"Selected features: {}\".format(np.array(features)[selector.get_support()]))\n",
    "print(\"Best R-squared on test data: {:.6f}\".format(max_accuracy))\n",
    "print(\"Selected features: {}\".format(best_features))\n",
    "\n",
    "# Print the RMSE values\n",
    "print(\"RMSE on train set: {:.6f}\".format(rmse_train))\n",
    "print(\"RMSE on test set: {:.6f}\".format(rmse_test))\n",
    "print(\"STD on test set: {:.2f}\".format(std_y_test))\n",
    "#23\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "max_accuracy = 0\n",
    "best_features = []\n",
    "\n",
    "df = pd.read_csv('../relevant csvs/power vector.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "for i in range(1,14):\n",
    "    # Load the data into a Pandas dataframe\n",
    "\n",
    "\n",
    "    # Define the target variable and the features you want to use for prediction\n",
    "    target = 'Power (J)'\n",
    "    features = ['Latitude','Longitude','Salinity', 'Temperature', 'Acidity','Alkalinity', 'Carbon','tecUHR','sunspot','Alk/Sal','Precipitation','TSI','CAPE']\n",
    "    #features = ['Longitude','Salinity', 'Temperature', 'Acidity', 'Alkalinity', 'Carbon','Alk/Sal','Precipitation']\n",
    "\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], np.log(df[target]), test_size=0.2, random_state=42)\n",
    "\n",
    "    # Use SelectKBest to select the top k features based on f_regression score\n",
    "    selector = SelectKBest(f_regression, k=i)\n",
    "    X_train = selector.fit_transform(X_train, y_train)\n",
    "    X_test = selector.transform(X_test)\n",
    "\n",
    "    # Create a linear regression model\n",
    "    #model = GradientBoostingRegressor(n_estimators=100, max_depth=3)\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model's performance using R-squared metric\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    if(r2>max_accuracy):\n",
    "            max_accuracy=r2\n",
    "            best_features = np.array(features)[selector.get_support()]\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            rmse_train = np.sqrt(mean_squared_error(np.exp(y_train), np.exp(y_pred_train)))\n",
    "            rmse_test = np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred)))\n",
    "            std_y_test = np.exp(y_test).std()\n",
    "    #print(\"R-squared on test data: {:.6f}\".format(r2))\n",
    "    #print(\"Selected features: {}\".format(np.array(features)[selector.get_support()]))\n",
    "print(\"Best R-squared on test data: {:.6f}\".format(max_accuracy))\n",
    "print(\"Selected features: {}\".format(best_features))\n",
    "\n",
    "print(\"RMSE on train set: {:.6f}\".format(rmse_train))\n",
    "print(\"RMSE on test set: {:.6f}\".format(rmse_test))\n",
    "print(\"STD on test set: {:.2f}\".format(std_y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R-squared on test data: 0.322629\n",
      "Selected features: ['Longitude' 'Salinity' 'Temperature' 'Acidity' 'Alkalinity' 'Carbon'\n",
      " 'tsi_1au' 'tsi_true_earth' 'Alk/Sal' 'Precipitation']\n",
      "RMSE on train set: 1.898551\n",
      "RMSE on test set: 1.785720\n",
      "STD on test set: 2.17\n"
     ]
    }
   ],
   "source": [
    "#GBoosting\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "max_accuracy = 0\n",
    "best_features = []\n",
    "\n",
    "df = pd.read_csv('../relevant csvs/Biogeochemistry power vector with prec.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "for i in range(1,14):\n",
    "\n",
    "    # Define the target variable and the features you want to use for prediction\n",
    "    target = 'Power (J)'\n",
    "    features = ['Latitude','Longitude','Salinity', 'Temperature', 'Acidity','Alkalinity', 'Carbon','tecUHR','sunspot','Alk/Sal','Precipitation','TSI','CAPE']\n",
    "    #features = ['Longitude','Salinity', 'Temperature', 'Acidity', 'Alkalinity', 'Carbon','Alk/Sal','Precipitation']\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], np.log(df[target]), test_size=0.2, random_state=42)\n",
    "\n",
    "    # Use SelectKBest to select the top k features based on f_regression score\n",
    "    selector = SelectKBest(f_regression, k=i)\n",
    "    X_train = selector.fit_transform(X_train, y_train)\n",
    "    X_test = selector.transform(X_test)\n",
    "\n",
    "    \n",
    "    for j in range(1,i+1):\n",
    "        #print(\"Max depth: {:.0f}\".format(j))\n",
    "        # Create a linear regression model\n",
    "        #model = GradientBoostingRegressor(n_estimators=100, max_depth=3)\n",
    "        model = GradientBoostingRegressor(n_estimators=100, max_depth=j)\n",
    "\n",
    "        # Fit the model to the training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model's performance using R-squared metric\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        if(r2>max_accuracy):\n",
    "            max_accuracy=r2\n",
    "            best_features = np.array(features)[selector.get_support()]\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            rmse_train = np.sqrt(mean_squared_error(np.exp(y_train), np.exp(y_pred_train)))\n",
    "            rmse_test = np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred)))\n",
    "            std_y_test = np.exp(y_test).std()\n",
    "        #print(\"R-squared on test data: {:.6f}\".format(r2))\n",
    "        #print(\"Selected features: {}\".format(np.array(features)[selector.get_support()]))\n",
    "print(\"Best R-squared on test data: {:.6f}\".format(max_accuracy))\n",
    "print(\"Selected features: {}\".format(best_features))\n",
    "\n",
    "print(\"RMSE on train set: {:.6f}\".format(rmse_train))\n",
    "print(\"RMSE on test set: {:.6f}\".format(rmse_test))\n",
    "print(\"STD on test set: {:.2f}\".format(std_y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R-squared on test data: 0.397163\n",
      "Selected features: ['Latitude' 'Longitude' 'Salinity' 'Temperature' 'Acidity' 'Alkalinity'\n",
      " 'Carbon' 'tecUHR' 'sunspot' 'Alk/Sal' 'Precipitation' 'TSI' 'CAPE']\n",
      "RMSE on train set: 84145.615985\n",
      "RMSE on test set: 84370.146639\n",
      "STD on test set: 85076.16\n"
     ]
    }
   ],
   "source": [
    "#GradientBoosting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "max_accuracy = 0\n",
    "best_features = []\n",
    "\n",
    "df = pd.read_csv('../relevant csvs/power vector.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "for i in range(1,14):\n",
    "    max_accuracy = 0\n",
    "    best_features = []\n",
    "    # Load the data into a Pandas dataframe\n",
    "\n",
    "    # Define the target variable and the features you want to use for prediction\n",
    "    target = 'Power (J)'\n",
    "    features = ['Latitude','Longitude','Salinity', 'Temperature', 'Acidity','Alkalinity', 'Carbon','tecUHR','sunspot','Alk/Sal','Precipitation','TSI','CAPE']\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], np.log(df[target]), test_size=0.3, random_state=42)\n",
    "\n",
    "    # Use SelectKBest to select the top k features based on f_regression score\n",
    "    selector = SelectKBest(f_regression, k=i)\n",
    "    X_train = selector.fit_transform(X_train, y_train)\n",
    "    X_test = selector.transform(X_test)\n",
    "\n",
    "    \n",
    "    for j in range(1,i+1):\n",
    "        #print(\"Max depth: {:.0f}\".format(j))\n",
    "        # Create a linear regression model\n",
    "        #model = GradientBoostingRegressor(n_estimators=100, max_depth=3)\n",
    "        model = GradientBoostingRegressor(n_estimators=100, max_depth=j)\n",
    "\n",
    "        # Fit the model to the training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model's performance using R-squared metric\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        if(r2>max_accuracy):\n",
    "            max_accuracy=r2\n",
    "            best_features = np.array(features)[selector.get_support()]\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            rmse_train = np.sqrt(mean_squared_error(np.exp(y_train), np.exp(y_pred_train)))\n",
    "            rmse_test = np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred)))\n",
    "            std_y_test = np.exp(y_test).std()\n",
    "        #print(\"R-squared on test data: {:.6f}\".format(r2))\n",
    "        #print(\"Selected features: {}\".format(np.array(features)[selector.get_support()]))\n",
    "print(\"Best R-squared on test data: {:.6f}\".format(max_accuracy))\n",
    "print(\"Selected features: {}\".format(best_features))\n",
    "\n",
    "# Print the RMSE values\n",
    "print(\"RMSE on train set: {:.6f}\".format(rmse_train))\n",
    "print(\"RMSE on test set: {:.6f}\".format(rmse_test))\n",
    "print(\"STD on test set: {:.2f}\".format(std_y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['sunspot'], dtype='object')\n",
      "Best R-squared on test data: 0.176844\n",
      "RMSE on train set: 88208.228541\n",
      "RMSE on test set: 86222.606046\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['sunspot', 'TSI'], dtype='object')\n",
      "Best R-squared on test data: 0.248761\n",
      "RMSE on train set: 88056.751080\n",
      "RMSE on test set: 86064.414765\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['tecUHR', 'sunspot', 'TSI'], dtype='object')\n",
      "Best R-squared on test data: 0.287979\n",
      "RMSE on train set: 88026.158380\n",
      "RMSE on test set: 86039.665923\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['tecUHR', 'sunspot', 'TSI', 'CAPE'], dtype='object')\n",
      "Best R-squared on test data: 0.287507\n",
      "RMSE on train set: 87970.419986\n",
      "RMSE on test set: 85987.920254\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Longitude', 'tecUHR', 'sunspot', 'TSI', 'CAPE'], dtype='object')\n",
      "Best R-squared on test data: 0.303336\n",
      "RMSE on train set: 87822.191535\n",
      "RMSE on test set: 85841.243192\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Latitude', 'Longitude', 'tecUHR', 'sunspot', 'TSI', 'CAPE'], dtype='object')\n",
      "Best R-squared on test data: 0.309794\n",
      "RMSE on train set: 87815.713440\n",
      "RMSE on test set: 85833.006083\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Latitude', 'Longitude', 'tecUHR', 'sunspot', 'Alk/Sal', 'TSI', 'CAPE'], dtype='object')\n",
      "Best R-squared on test data: 0.305271\n",
      "RMSE on train set: 87840.386344\n",
      "RMSE on test set: 85869.474515\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Latitude', 'Longitude', 'Temperature', 'tecUHR', 'sunspot', 'Alk/Sal',\n",
      "       'TSI', 'CAPE'],\n",
      "      dtype='object')\n",
      "Best R-squared on test data: 0.307381\n",
      "RMSE on train set: 87801.382495\n",
      "RMSE on test set: 85827.239872\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Latitude', 'Longitude', 'Temperature', 'tecUHR', 'sunspot', 'Alk/Sal',\n",
      "       'Precipitation', 'TSI', 'CAPE'],\n",
      "      dtype='object')\n",
      "Best R-squared on test data: 0.308381\n",
      "RMSE on train set: 87817.954694\n",
      "RMSE on test set: 85847.883874\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Latitude', 'Longitude', 'Temperature', 'Carbon', 'tecUHR', 'sunspot',\n",
      "       'Alk/Sal', 'Precipitation', 'TSI', 'CAPE'],\n",
      "      dtype='object')\n",
      "Best R-squared on test data: 0.305419\n",
      "RMSE on train set: 87804.395461\n",
      "RMSE on test set: 85843.259483\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Latitude', 'Longitude', 'Temperature', 'Alkalinity', 'Carbon',\n",
      "       'tecUHR', 'sunspot', 'Alk/Sal', 'Precipitation', 'TSI', 'CAPE'],\n",
      "      dtype='object')\n",
      "Best R-squared on test data: 0.304190\n",
      "RMSE on train set: 87815.120546\n",
      "RMSE on test set: 85846.343622\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Latitude', 'Longitude', 'Temperature', 'Acidity', 'Alkalinity',\n",
      "       'Carbon', 'tecUHR', 'sunspot', 'Alk/Sal', 'Precipitation', 'TSI',\n",
      "       'CAPE'],\n",
      "      dtype='object')\n",
      "Best R-squared on test data: 0.304306\n",
      "RMSE on train set: 87803.230933\n",
      "RMSE on test set: 85849.086873\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Latitude', 'Longitude', 'Salinity', 'Temperature', 'Acidity',\n",
      "       'Alkalinity', 'Carbon', 'tecUHR', 'sunspot', 'Alk/Sal', 'Precipitation',\n",
      "       'TSI', 'CAPE'],\n",
      "      dtype='object')\n",
      "Best R-squared on test data: 0.305718\n",
      "RMSE on train set: 87810.519469\n",
      "RMSE on test set: 85860.615163\n",
      "--------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#feature selection with xvalidation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Load the data into a Pandas dataframe\n",
    "df = pd.read_csv('../relevant csvs/power vector.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "# Define the target variable and the features you want to use for prediction\n",
    "target = 'Power (J)'\n",
    "all_features = ['Latitude', 'Longitude', 'Salinity', 'Temperature', 'Acidity',\n",
    "                'Alkalinity', 'Carbon', 'tecUHR',\n",
    "                'sunspot', 'Alk/Sal', 'Precipitation',\n",
    "                \"TSI\", 'CAPE']\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "# Create a KFold cross-validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=77)\n",
    "\n",
    "for i in range(1, 14):\n",
    "    # Create a XGBoost regressor model\n",
    "    model = XGBRegressor(n_estimators=20)\n",
    "\n",
    "    # Use RFE for feature selection\n",
    "    rfe = RFE(model, n_features_to_select=i)\n",
    "\n",
    "    # Keep track of the performance metrics for each fold\n",
    "    r2_scores = []\n",
    "    rmse_train_scores = []\n",
    "    rmse_test_scores = []\n",
    "\n",
    "    # Iterate over the folds and train/evaluate the model\n",
    "    for train_idx, test_idx in kfold.split(df[all_features]):\n",
    "        # Split the data into training and test sets for the current fold\n",
    "        X_train, X_test = df.iloc[train_idx][all_features], df.iloc[test_idx][all_features]\n",
    "        y_train, y_test = np.log(df.iloc[train_idx][target]), np.log(df.iloc[test_idx][target])\n",
    "\n",
    "        # Fit the RFE model to the training data and select the features\n",
    "        rfe.fit(X_train, y_train)\n",
    "        selected_features = X_train.columns[rfe.support_]\n",
    "\n",
    "        # Fit the XGBoost model to the selected features\n",
    "        model.fit(X_train[selected_features], y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = model.predict(X_test[selected_features])\n",
    "\n",
    "        # Evaluate the model's performance using R-squared metric\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "        # Compute RMSE on the train and test data for the current fold\n",
    "        y_pred_train = model.predict(X_train[selected_features])\n",
    "        rmse_train = np.sqrt(mean_squared_error(np.exp(y_train), np.exp(y_pred_train)))\n",
    "        rmse_train_scores.append(rmse_train)\n",
    "\n",
    "        rmse_test = np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred)))\n",
    "        rmse_test_scores.append(rmse_test)\n",
    "\n",
    "    # Compute the mean and standard deviation of the performance metrics over all folds\n",
    "    mean_r2 = np.mean(r2_scores)\n",
    "    mean_rmse_train = np.mean(rmse_train_scores)\n",
    "    mean_rmse_test = np.mean(rmse_test_scores)\n",
    "    std_rmse_test = np.std(rmse_test_scores)\n",
    "\n",
    "    # Print the results for the current value of i\n",
    "    print(\"Selected features: {}\".format(selected_features))\n",
    "    print(\"Best R-squared on test data: {:.6f}\".format(r2))\n",
    "    print(\"RMSE on train set: {:.6f}\".format(rmse_train))\n",
    "    print(\"RMSE on test set: {:.6f}\".format(rmse_test))\n",
    "    print(\"--------------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R-squared on test data: 0.202124\n",
      "Selected features: ['Latitude' 'Longitude' 'Salinity' 'Temperature' 'Acidity' 'Alkalinity'\n",
      " 'Carbon' 'Precipitation']\n",
      "RMSE on train set: 250.416534\n",
      "RMSE on test set: 252.443249\n",
      "STD on test set: 254.67\n"
     ]
    }
   ],
   "source": [
    "#LinearRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "max_accuracy = 0\n",
    "best_features = []\n",
    "\n",
    "for i in range(1,9):\n",
    "    # Load the data into a Pandas dataframe\n",
    "    df = pd.read_csv(\"../RELEVANT CSVS/frequency for correlation.csv\")\n",
    "    \n",
    "\n",
    "    # Define the target variable and the features you want to use for prediction\n",
    "    target = 'Count'\n",
    "    features = ['Latitude','Longitude','Salinity', 'Temperature', 'Acidity','Alkalinity', 'Carbon', 'Precipitation']\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], np.log(df[target]), test_size=0.3, random_state=42)\n",
    "\n",
    "    # Use SelectKBest to select the top k features based on f_regression score\n",
    "    selector = SelectKBest(f_regression, k=i)\n",
    "    X_train = selector.fit_transform(X_train, y_train)\n",
    "    X_test = selector.transform(X_test)\n",
    "\n",
    "    # Create a linear regression model\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model's performance using R-squared metric\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    if(r2>max_accuracy):\n",
    "            max_accuracy=r2\n",
    "            best_features = np.array(features)[selector.get_support()]\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            rmse_train = np.sqrt(mean_squared_error(np.exp(y_train), np.exp(y_pred_train)))\n",
    "            rmse_test = np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred)))\n",
    "            std_y_test = np.exp(y_test).std()\n",
    "    #print(\"R-squared on test data: {:.6f}\".format(r2))\n",
    "    #print(\"Selected features: {}\".format(np.array(features)[selector.get_support()]))\n",
    "print(\"Best R-squared on test data: {:.6f}\".format(max_accuracy))\n",
    "print(\"Selected features: {}\".format(best_features))\n",
    "# Compute RMSE on the train set\n",
    "\n",
    "# Print the RMSE values\n",
    "print(\"RMSE on train set: {:.6f}\".format(rmse_train))\n",
    "print(\"RMSE on test set: {:.6f}\".format(rmse_test))\n",
    "print(\"STD on test set: {:.2f}\".format(std_y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R-squared on test data: 0.406420\n",
      "Selected features: ['Latitude' 'Longitude' 'Salinity' 'Temperature' 'Acidity' 'Alkalinity'\n",
      " 'Carbon' 'tecUHR' \"('sunspot', 'count')\" 'Precipitation'\n",
      " \"('TSI', 'mean')\" 'CAPE']\n",
      "RMSE on train set: 195.563170\n",
      "RMSE on test set: 208.637665\n",
      "STD on test set: 254.67\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "max_accuracy = 0\n",
    "best_features = []\n",
    "\n",
    "for i in range(1,15):\n",
    "    # Load the data into a Pandas dataframe\n",
    "    df = pd.read_csv('../relevant csvs/frequency for correlation.csv')\n",
    "    df = df.dropna()\n",
    "\n",
    "\n",
    "    # Define the target variable and the features you want to use for prediction\n",
    "    target = 'Count'\n",
    "    features = ['Latitude','Longitude','Salinity', 'Temperature', 'Acidity','Alkalinity', 'Carbon','tecUHR',\"('sunspot', 'mean')\",\"('sunspot', 'count')\",'Alk/Sal','Precipitation',\"('TSI', 'mean')\",'CAPE']\n",
    "\n",
    "\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], np.log(df[target]), test_size=0.3, random_state=42)\n",
    "\n",
    "    # Use SelectKBest to select the top k features based on f_regression score\n",
    "    selector = SelectKBest(f_regression, k=i)\n",
    "    X_train = selector.fit_transform(X_train, y_train)\n",
    "    X_test = selector.transform(X_test)\n",
    "\n",
    "    \n",
    "    for j in range(1,i+1):\n",
    "        #print(\"Max depth: {:.0f}\".format(j))\n",
    "        # Create a linear regression model\n",
    "        #model = GradientBoostingRegressor(n_estimators=100, max_depth=3)\n",
    "        model = DecisionTreeRegressor(max_depth=j)\n",
    "\n",
    "        # Fit the model to the training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model's performance using R-squared metric\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        if(r2>max_accuracy):\n",
    "            max_accuracy=r2\n",
    "            best_features = np.array(features)[selector.get_support()]\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            rmse_train = np.sqrt(mean_squared_error(np.exp(y_train), np.exp(y_pred_train)))\n",
    "            rmse_test = np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred)))\n",
    "            std_y_test = np.exp(y_test).std()\n",
    "        #print(\"R-squared on test data: {:.6f}\".format(r2))\n",
    "        #print(\"Selected features: {}\".format(np.array(features)[selector.get_support()]))\n",
    "print(\"Best R-squared on test data: {:.6f}\".format(max_accuracy))\n",
    "print(\"Selected features: {}\".format(best_features))\n",
    "\n",
    "# Print the RMSE values\n",
    "print(\"RMSE on train set: {:.6f}\".format(rmse_train))\n",
    "print(\"RMSE on test set: {:.6f}\".format(rmse_test))\n",
    "print(\"STD on test set: {:.2f}\".format(std_y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R-squared on test data: 0.575735\n",
      "Selected features: ['Latitude' 'Longitude' 'Salinity' 'Temperature' 'Acidity' 'Alkalinity'\n",
      " 'Carbon' 'tecUHR' \"('sunspot', 'mean')\" \"('sunspot', 'count')\"\n",
      " 'Precipitation' \"('TSI', 'mean')\" 'CAPE']\n",
      "RMSE on train set: 102.058034\n",
      "RMSE on test set: 180.531508\n",
      "STD on test set: 254.67\n"
     ]
    }
   ],
   "source": [
    "#RandomForest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "max_accuracy = 0\n",
    "best_features = []\n",
    "\n",
    "\n",
    "for i in range(1,15):\n",
    "    # Load the data into a Pandas dataframe\n",
    "    df = pd.read_csv('../relevant csvs/Frequency for correlation.csv')\n",
    "    df = df.dropna()\n",
    "\n",
    "\n",
    "    # Define the target variable and the features you want to use for prediction\n",
    "    target = 'Count'\n",
    "    features = ['Latitude','Longitude','Salinity', 'Temperature', 'Acidity','Alkalinity', 'Carbon','tecUHR',\"('sunspot', 'mean')\",\"('sunspot', 'count')\",'Alk/Sal','Precipitation',\"('TSI', 'mean')\",'CAPE']\n",
    "\n",
    "\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], np.log(df[target]), test_size=0.3, random_state=42)\n",
    "\n",
    "    # Use SelectKBest to select the top k features based on f_regression score\n",
    "    selector = SelectKBest(f_regression, k=i)\n",
    "    X_train = selector.fit_transform(X_train, y_train)\n",
    "    X_test = selector.transform(X_test)\n",
    "\n",
    "    # Create a linear regression model\n",
    "    #model = GradientBoostingRegressor(n_estimators=100, max_depth=3)\n",
    "    model = RandomForestRegressor(n_estimators=20, random_state=42)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model's performance using R-squared metric\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    if(r2>max_accuracy):\n",
    "            max_accuracy=r2\n",
    "            best_features = np.array(features)[selector.get_support()]\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            rmse_train = np.sqrt(mean_squared_error(np.exp(y_train), np.exp(y_pred_train)))\n",
    "            rmse_test = np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred)))\n",
    "            std_y_test = np.exp(y_test).std()\n",
    "    #print(\"R-squared on test data: {:.6f}\".format(r2))\n",
    "    #print(\"Selected features: {}\".format(np.array(features)[selector.get_support()]))\n",
    "print(\"Best R-squared on test data: {:.6f}\".format(max_accuracy))\n",
    "print(\"Selected features: {}\".format(best_features))\n",
    "\n",
    "# Print the RMSE values\n",
    "print(\"RMSE on train set: {:.6f}\".format(rmse_train))\n",
    "print(\"RMSE on test set: {:.6f}\".format(rmse_test))\n",
    "print(\"STD on test set: {:.2f}\".format(std_y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R-squared on test data: 0.644193\n",
      "Selected features: ['Latitude' 'Longitude' 'Salinity' 'Temperature' 'Acidity' 'Alkalinity'\n",
      " 'Carbon' 'tecUHR' \"('sunspot', 'mean')\" \"('sunspot', 'count')\"\n",
      " 'Precipitation' \"('TSI', 'mean')\" 'CAPE']\n",
      "RMSE on train set: 131.403630\n",
      "RMSE on test set: 184.066372\n",
      "STD on test set: 262.84\n"
     ]
    }
   ],
   "source": [
    "#GradientBoosting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "max_accuracy = 0\n",
    "best_features = []\n",
    "\n",
    "for i in range(1,15):\n",
    "    # Load the data into a Pandas dataframe\n",
    "    df = pd.read_csv('../relevant csvs/Frequency for correlation.csv')\n",
    "    df = df.dropna()\n",
    "\n",
    "\n",
    "    # Define the target variable and the features you want to use for prediction\n",
    "    target = 'Count'\n",
    "    features = ['Latitude','Longitude','Salinity', 'Temperature', 'Acidity','Alkalinity', 'Carbon','tecUHR',\"('sunspot', 'mean')\",\"('sunspot', 'count')\",'Alk/Sal','Precipitation',\"('TSI', 'mean')\",'CAPE']\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], np.log(df[target]), test_size=0.3, random_state=66)\n",
    "\n",
    "    # Use SelectKBest to select the top k features based on f_regression score\n",
    "    selector = SelectKBest(f_regression, k=i)\n",
    "    X_train = selector.fit_transform(X_train, y_train)\n",
    "    X_test = selector.transform(X_test)\n",
    "\n",
    "    \n",
    "    for j in range(1,i+1):\n",
    "        #print(\"Max depth: {:.0f}\".format(j))\n",
    "        # Create a linear regression model\n",
    "        #model = GradientBoostingRegressor(n_estimators=100, max_depth=3)\n",
    "        model = GradientBoostingRegressor(n_estimators=100, max_depth=j)\n",
    "\n",
    "        # Fit the model to the training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model's performance using R-squared metric\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        if(r2>max_accuracy):\n",
    "            max_accuracy=r2\n",
    "            best_features = np.array(features)[selector.get_support()]\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            rmse_train = np.sqrt(mean_squared_error(np.exp(y_train), np.exp(y_pred_train)))\n",
    "            rmse_test = np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred)))\n",
    "            std_y_test = np.exp(y_test).std()\n",
    "        #print(\"R-squared on test data: {:.6f}\".format(r2))\n",
    "        #print(\"Selected features: {}\".format(np.array(features)[selector.get_support()]))\n",
    "print(\"Best R-squared on test data: {:.6f}\".format(max_accuracy))\n",
    "print(\"Selected features: {}\".format(best_features))\n",
    "\n",
    "# Print the RMSE values\n",
    "print(\"RMSE on train set: {:.6f}\".format(rmse_train))\n",
    "print(\"RMSE on test set: {:.6f}\".format(rmse_test))\n",
    "print(\"STD on test set: {:.2f}\".format(std_y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['tecUHR'], dtype='object')\n",
      "Best R-squared on test data: 0.282965\n",
      "RMSE on train set: 48349.224735\n",
      "RMSE on test set: 38693.099826\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['tecUHR', 'ss_mean'], dtype='object')\n",
      "Best R-squared on test data: 0.282906\n",
      "RMSE on train set: 48348.226754\n",
      "RMSE on test set: 38692.312218\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['tecUHR', 'ss_mean', 'TSI'], dtype='object')\n",
      "Best R-squared on test data: 0.282835\n",
      "RMSE on train set: 48344.147000\n",
      "RMSE on test set: 38689.493242\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['tecUHR', 'ss_mean', 'TSI', 'CAPE'], dtype='object')\n",
      "Best R-squared on test data: 0.298242\n",
      "RMSE on train set: 47319.069541\n",
      "RMSE on test set: 38489.891945\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['tecUHR', 'ss_mean', 'Precipitation', 'TSI', 'CAPE'], dtype='object')\n",
      "Best R-squared on test data: 0.284884\n",
      "RMSE on train set: 46032.069133\n",
      "RMSE on test set: 38328.263155\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['tecUHR', 'ss_mean', 'Alk/Sal', 'Precipitation', 'TSI', 'CAPE'], dtype='object')\n",
      "Best R-squared on test data: 0.300792\n",
      "RMSE on train set: 45970.853956\n",
      "RMSE on test set: 37961.165716\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Alkalinity', 'tecUHR', 'ss_mean', 'Alk/Sal', 'Precipitation', 'TSI',\n",
      "       'CAPE'],\n",
      "      dtype='object')\n",
      "Best R-squared on test data: 0.328404\n",
      "RMSE on train set: 45367.448233\n",
      "RMSE on test set: 37850.075360\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Acidity', 'Alkalinity', 'tecUHR', 'ss_mean', 'Alk/Sal',\n",
      "       'Precipitation', 'TSI', 'CAPE'],\n",
      "      dtype='object')\n",
      "Best R-squared on test data: 0.332621\n",
      "RMSE on train set: 45328.549752\n",
      "RMSE on test set: 37640.985610\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Temperature', 'Acidity', 'Alkalinity', 'tecUHR', 'ss_mean', 'Alk/Sal',\n",
      "       'Precipitation', 'TSI', 'CAPE'],\n",
      "      dtype='object')\n",
      "Best R-squared on test data: 0.333696\n",
      "RMSE on train set: 44584.302491\n",
      "RMSE on test set: 37440.340955\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Longitude', 'Temperature', 'Acidity', 'Alkalinity', 'tecUHR',\n",
      "       'ss_mean', 'Alk/Sal', 'Precipitation', 'TSI', 'CAPE'],\n",
      "      dtype='object')\n",
      "Best R-squared on test data: 0.348852\n",
      "RMSE on train set: 44339.621943\n",
      "RMSE on test set: 37113.717890\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Latitude', 'Longitude', 'Temperature', 'Acidity', 'Alkalinity',\n",
      "       'tecUHR', 'ss_mean', 'Alk/Sal', 'Precipitation', 'TSI', 'CAPE'],\n",
      "      dtype='object')\n",
      "Best R-squared on test data: 0.355421\n",
      "RMSE on train set: 43676.054001\n",
      "RMSE on test set: 36748.972643\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Latitude', 'Longitude', 'Temperature', 'Acidity', 'Alkalinity',\n",
      "       'Carbon', 'tecUHR', 'ss_mean', 'Alk/Sal', 'Precipitation', 'TSI',\n",
      "       'CAPE'],\n",
      "      dtype='object')\n",
      "Best R-squared on test data: 0.353356\n",
      "RMSE on train set: 44442.280124\n",
      "RMSE on test set: 37387.185569\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Latitude', 'Longitude', 'Salinity', 'Temperature', 'Acidity',\n",
      "       'Alkalinity', 'Carbon', 'tecUHR', 'ss_mean', 'Alk/Sal', 'Precipitation',\n",
      "       'TSI', 'CAPE'],\n",
      "      dtype='object')\n",
      "Best R-squared on test data: 0.351628\n",
      "RMSE on train set: 44247.543628\n",
      "RMSE on test set: 37292.190694\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Latitude', 'Longitude', 'Salinity', 'Temperature', 'Acidity',\n",
      "       'Alkalinity', 'Carbon', 'tecUHR', 'ss_mean', 'ss_count', 'Alk/Sal',\n",
      "       'Precipitation', 'TSI', 'CAPE'],\n",
      "      dtype='object')\n",
      "Best R-squared on test data: 0.360611\n",
      "RMSE on train set: 44202.773310\n",
      "RMSE on test set: 36983.442492\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#feature selection with xvalidation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Load the data into a Pandas dataframe\n",
    "df = pd.read_csv('../relevant csvs/Frequency for correlation.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "# Define the target variable and the features you want to use for prediction\n",
    "target = 'Power (J)_mean'\n",
    "all_features = ['Latitude', 'Longitude', 'Salinity', 'Temperature', 'Acidity',\n",
    "                'Alkalinity', 'Carbon', 'tecUHR', \"ss_mean\",\n",
    "                'ss_count', 'Alk/Sal', 'Precipitation',\n",
    "                \"TSI\", 'CAPE']\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "# Create a KFold cross-validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=77)\n",
    "\n",
    "for i in range(1, 15):\n",
    "    # Create a XGBoost regressor model\n",
    "    model = XGBRegressor(n_estimators=20)\n",
    "\n",
    "    # Use RFE for feature selection\n",
    "    rfe = RFE(model, n_features_to_select=i)\n",
    "\n",
    "    # Keep track of the performance metrics for each fold\n",
    "    r2_scores = []\n",
    "    rmse_train_scores = []\n",
    "    rmse_test_scores = []\n",
    "\n",
    "    # Iterate over the folds and train/evaluate the model\n",
    "    for train_idx, test_idx in kfold.split(df[all_features]):\n",
    "        # Split the data into training and test sets for the current fold\n",
    "        X_train, X_test = df.iloc[train_idx][all_features], df.iloc[test_idx][all_features]\n",
    "        y_train, y_test = np.log(df.iloc[train_idx][target]), np.log(df.iloc[test_idx][target])\n",
    "\n",
    "        # Fit the RFE model to the training data and select the features\n",
    "        rfe.fit(X_train, y_train)\n",
    "        selected_features = X_train.columns[rfe.support_]\n",
    "\n",
    "        # Fit the XGBoost model to the selected features\n",
    "        model.fit(X_train[selected_features], y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = model.predict(X_test[selected_features])\n",
    "\n",
    "        # Evaluate the model's performance using R-squared metric\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "        # Compute RMSE on the train and test data for the current fold\n",
    "        y_pred_train = model.predict(X_train[selected_features])\n",
    "        rmse_train = np.sqrt(mean_squared_error(np.exp(y_train), np.exp(y_pred_train)))\n",
    "        rmse_train_scores.append(rmse_train)\n",
    "\n",
    "        rmse_test = np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred)))\n",
    "        rmse_test_scores.append(rmse_test)\n",
    "\n",
    "    # Compute the mean and standard deviation of the performance metrics over all folds\n",
    "    mean_r2 = np.mean(r2_scores)\n",
    "    mean_rmse_train = np.mean(rmse_train_scores)\n",
    "    mean_rmse_test = np.mean(rmse_test_scores)\n",
    "    std_rmse_test = np.std(rmse_test_scores)\n",
    "    std_y_test = np.exp(y_test).std()\n",
    "\n",
    "\n",
    "    # Print the results for the current value of i\n",
    "    print(\"Selected features: {}\".format(selected_features))\n",
    "    print(\"Best R-squared on test data: {:.6f}\".format(r2))\n",
    "    print(\"RMSE on train set: {:.6f}\".format(rmse_train))\n",
    "    print(\"RMSE on test set: {:.6f}\".format(rmse_test))\n",
    "    print(\"STD on test set: {:.2f}\".format(std_y_test))\n",
    "    print(\"--------------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['Latitude', 'Longitude', 'Salinity', 'Temperature', 'Acidity',\n",
      "       'Alkalinity', 'Carbon', 'tecUHR', 'ss_count', 'Alk/Sal',\n",
      "       'Precipitation', 'TSI', 'CAPE'],\n",
      "      dtype='object')\n",
      "Best R-squared on test data: 0.585545\n",
      "RMSE on train set: 170.772192\n",
      "RMSE on test set: 213.026507\n",
      "STD on test set: 254.67\n",
      "--------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#feature selection test\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Load the data into a Pandas dataframe\n",
    "df = pd.read_csv('../relevant csvs/Frequency for correlation.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "# Define the target variable and the features you want to use for prediction\n",
    "target = 'Count'\n",
    "all_features = ['Latitude', 'Longitude', 'Salinity', 'Temperature', 'Acidity',\n",
    "                'Alkalinity', 'Carbon', 'tecUHR',\n",
    "                'ss_count', 'Alk/Sal', 'Precipitation',\n",
    "                \"TSI\", 'CAPE']\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "# Create a KFold cross-validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=77)\n",
    "\n",
    "# Create a XGBoost regressor model\n",
    "model = XGBRegressor(n_estimators=20)\n",
    "\n",
    "# Use RFE for feature selection\n",
    "rfe = RFE(model, n_features_to_select=14)\n",
    "\n",
    "# Keep track of the performance metrics for each fold\n",
    "r2_scores = []\n",
    "rmse_train_scores = []\n",
    "rmse_test_scores = []\n",
    "\n",
    "# Iterate over the folds and train/evaluate the model\n",
    "for train_idx, test_idx in kfold.split(df[all_features]):\n",
    "    # Split the data into training and test sets for the current fold\n",
    "    X_train, X_test = df.iloc[train_idx][all_features], df.iloc[test_idx][all_features]\n",
    "    y_train, y_test = np.log(df.iloc[train_idx][target]), np.log(df.iloc[test_idx][target])\n",
    "\n",
    "    # Fit the RFE model to the training data and select the features\n",
    "    rfe.fit(X_train, y_train)\n",
    "    selected_features = X_train.columns[rfe.support_]\n",
    "\n",
    "    # Fit the XGBoost model to the selected features\n",
    "    model.fit(X_train[selected_features], y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test[selected_features])\n",
    "\n",
    "    # Evaluate the model's performance using R-squared metric\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "    # Compute RMSE on the train and test data for the current fold\n",
    "    y_pred_train = model.predict(X_train[selected_features])\n",
    "    rmse_train = np.sqrt(mean_squared_error(np.exp(y_train), np.exp(y_pred_train)))\n",
    "    rmse_train_scores.append(rmse_train)\n",
    "\n",
    "    rmse_test = np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred)))\n",
    "    rmse_test_scores.append(rmse_test)\n",
    "\n",
    "# Compute the mean and standard deviation of the performance metrics over all folds\n",
    "mean_r2 = np.mean(r2_scores)\n",
    "mean_rmse_train = np.mean(rmse_train_scores)\n",
    "mean_rmse_test = np.mean(rmse_test_scores)\n",
    "std_rmse_test = np.std(rmse_test_scores)\n",
    "\n",
    "# Print the results for the current value of i\n",
    "print(\"Selected features: {}\".format(selected_features))\n",
    "print(\"Best R-squared on test data: {:.6f}\".format(r2))\n",
    "print(\"RMSE on train set: {:.6f}\".format(rmse_train))\n",
    "print(\"RMSE on test set: {:.6f}\".format(rmse_test))\n",
    "print(\"STD on test set: {:.2f}\".format(std_y_test))\n",
    "print(\"--------------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R-squared on test data: 0.402651\n",
      "Selected features: ['Latitude' 'Longitude' 'Salinity' 'Temperature' 'Acidity' 'Alkalinity'\n",
      " 'Carbon' 'tecUHR' 'ss_mean' 'Alk/Sal' 'Precipitation' 'TSI' 'CAPE']\n",
      "RMSE on train set: 29547.727328\n",
      "RMSE on test set: 36946.597735\n",
      "STD on test set: 41661.10\n"
     ]
    }
   ],
   "source": [
    "#GradientBoosting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "max_accuracy = 0\n",
    "best_features = []\n",
    "\n",
    "df = pd.read_csv('../relevant csvs/frequency for correlation.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "for i in range(1,14):\n",
    "    max_accuracy = 0\n",
    "    best_features = []\n",
    "    # Load the data into a Pandas dataframe\n",
    "\n",
    "    # Define the target variable and the features you want to use for prediction\n",
    "    target = 'Power (J)_mean'\n",
    "    features = ['Latitude','Longitude','Salinity', 'Temperature', 'Acidity','Alkalinity', 'Carbon','tecUHR',\"ss_mean\",\"ss_count\",'Alk/Sal','Precipitation',\"TSI\",'CAPE']\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], np.log(df[target]), test_size=0.3, random_state=42)\n",
    "\n",
    "    # Use SelectKBest to select the top k features based on f_regression score\n",
    "    selector = SelectKBest(f_regression, k=i)\n",
    "    X_train = selector.fit_transform(X_train, y_train)\n",
    "    X_test = selector.transform(X_test)\n",
    "\n",
    "    \n",
    "    for j in range(1,i+1):\n",
    "        #print(\"Max depth: {:.0f}\".format(j))\n",
    "        # Create a linear regression model\n",
    "        #model = GradientBoostingRegressor(n_estimators=100, max_depth=3)\n",
    "        model = GradientBoostingRegressor(n_estimators=100, max_depth=j)\n",
    "\n",
    "        # Fit the model to the training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model's performance using R-squared metric\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        if(r2>max_accuracy):\n",
    "            max_accuracy=r2\n",
    "            best_features = np.array(features)[selector.get_support()]\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            rmse_train = np.sqrt(mean_squared_error(np.exp(y_train), np.exp(y_pred_train)))\n",
    "            rmse_test = np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred)))\n",
    "            std_y_test = np.exp(y_test).std()\n",
    "        #print(\"R-squared on test data: {:.6f}\".format(r2))\n",
    "        #print(\"Selected features: {}\".format(np.array(features)[selector.get_support()]))\n",
    "print(\"Best R-squared on test data: {:.6f}\".format(max_accuracy))\n",
    "print(\"Selected features: {}\".format(best_features))\n",
    "\n",
    "# Print the RMSE values\n",
    "print(\"RMSE on train set: {:.6f}\".format(rmse_train))\n",
    "print(\"RMSE on test set: {:.6f}\".format(rmse_test))\n",
    "print(\"STD on test set: {:.2f}\".format(std_y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Month', 'Latitude', 'Longitude',\n",
    "            \"ss_mean\", \"ss_count\", \"TSI\", 'tecUHR','CAPE',\n",
    "            'Power (J)_mean', 'Power (J)_sum','Count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['TSI'], dtype='object')\n",
      "Best R-squared on test data: 0.170168\n",
      "RMSE on train set: 50062.371616\n",
      "RMSE on test set: 40649.392684\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['TSI', 'tecUHR'], dtype='object')\n",
      "Best R-squared on test data: 0.172965\n",
      "RMSE on train set: 49984.544613\n",
      "RMSE on test set: 40516.552898\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['ss_count', 'TSI', 'tecUHR'], dtype='object')\n",
      "Best R-squared on test data: 0.172994\n",
      "RMSE on train set: 49986.449590\n",
      "RMSE on test set: 40519.131710\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['ss_mean', 'ss_count', 'TSI', 'tecUHR'], dtype='object')\n",
      "Best R-squared on test data: 0.200459\n",
      "RMSE on train set: 49552.655124\n",
      "RMSE on test set: 39990.646449\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Latitude', 'ss_mean', 'ss_count', 'TSI', 'tecUHR'], dtype='object')\n",
      "Best R-squared on test data: 0.200015\n",
      "RMSE on train set: 49431.684545\n",
      "RMSE on test set: 39948.879928\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Latitude', 'ss_mean', 'ss_count', 'TSI', 'tecUHR', 'CAPE'], dtype='object')\n",
      "Best R-squared on test data: 0.201058\n",
      "RMSE on train set: 49344.728520\n",
      "RMSE on test set: 39872.531093\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Latitude', 'Longitude', 'ss_mean', 'ss_count', 'TSI', 'tecUHR',\n",
      "       'CAPE'],\n",
      "      dtype='object')\n",
      "Best R-squared on test data: 0.201444\n",
      "RMSE on train set: 49336.893759\n",
      "RMSE on test set: 39864.940571\n",
      "STD on test set: 40680.83\n",
      "--------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#feature selection with xvalidation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Load the data into a Pandas dataframe\n",
    "df = pd.read_csv('../relevant csvs/Frequency for correlation.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "# Define the target variable and the features you want to use for prediction\n",
    "target = 'Power (J)_mean'\n",
    "all_features = ['Latitude', 'Longitude',\n",
    "            \"ss_mean\", \"ss_count\", \"TSI\", 'tecUHR','CAPE']\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "# Create a KFold cross-validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=77)\n",
    "\n",
    "for i in range(1, 8):\n",
    "    # Create a XGBoost regressor model\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Use RFE for feature selection\n",
    "    rfe = RFE(model, n_features_to_select=i)\n",
    "\n",
    "    # Keep track of the performance metrics for each fold\n",
    "    r2_scores = []\n",
    "    rmse_train_scores = []\n",
    "    rmse_test_scores = []\n",
    "\n",
    "    # Iterate over the folds and train/evaluate the model\n",
    "    for train_idx, test_idx in kfold.split(df[all_features]):\n",
    "        # Split the data into training and test sets for the current fold\n",
    "        X_train, X_test = df.iloc[train_idx][all_features], df.iloc[test_idx][all_features]\n",
    "        y_train, y_test = np.log(df.iloc[train_idx][target]), np.log(df.iloc[test_idx][target])\n",
    "\n",
    "        # Fit the RFE model to the training data and select the features\n",
    "        rfe.fit(X_train, y_train)\n",
    "        selected_features = X_train.columns[rfe.support_]\n",
    "\n",
    "        # Fit the XGBoost model to the selected features\n",
    "        model.fit(X_train[selected_features], y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = model.predict(X_test[selected_features])\n",
    "\n",
    "        # Evaluate the model's performance using R-squared metric\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "        # Compute RMSE on the train and test data for the current fold\n",
    "        y_pred_train = model.predict(X_train[selected_features])\n",
    "        rmse_train = np.sqrt(mean_squared_error(np.exp(y_train), np.exp(y_pred_train)))\n",
    "        rmse_train_scores.append(rmse_train)\n",
    "\n",
    "        rmse_test = np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred)))\n",
    "        rmse_test_scores.append(rmse_test)\n",
    "\n",
    "    # Compute the mean and standard deviation of the performance metrics over all folds\n",
    "    mean_r2 = np.mean(r2_scores)\n",
    "    mean_rmse_train = np.mean(rmse_train_scores)\n",
    "    mean_rmse_test = np.mean(rmse_test_scores)\n",
    "    std_rmse_test = np.std(rmse_test_scores)\n",
    "    std_y_test = np.exp(y_test).std()\n",
    "\n",
    "\n",
    "    # Print the results for the current value of i\n",
    "    print(\"Selected features: {}\".format(selected_features))\n",
    "    print(\"Best R-squared on test data: {:.6f}\".format(r2))\n",
    "    print(\"RMSE on train set: {:.6f}\".format(rmse_train))\n",
    "    print(\"RMSE on test set: {:.6f}\".format(rmse_test))\n",
    "    print(\"STD on test set: {:.2f}\".format(std_y_test))\n",
    "    print(\"--------------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['TSI'], dtype='object')\n",
      "Best R-squared on test data: 0.126841\n",
      "RMSE on train set: 4832803.021564\n",
      "RMSE on test set: 4921277.179802\n",
      "STD on test set: 4832140.13\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['TSI', 'CAPE'], dtype='object')\n",
      "Best R-squared on test data: 0.345025\n",
      "RMSE on train set: 4139090.987650\n",
      "RMSE on test set: 4331612.347017\n",
      "STD on test set: 4832140.13\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['TSI', 'tecUHR', 'CAPE'], dtype='object')\n",
      "Best R-squared on test data: 0.351979\n",
      "RMSE on train set: 4104514.184306\n",
      "RMSE on test set: 4297745.789617\n",
      "STD on test set: 4832140.13\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['ss_mean', 'TSI', 'tecUHR', 'CAPE'], dtype='object')\n",
      "Best R-squared on test data: 0.350227\n",
      "RMSE on train set: 4091910.748367\n",
      "RMSE on test set: 4284271.565565\n",
      "STD on test set: 4832140.13\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Longitude', 'ss_mean', 'TSI', 'tecUHR', 'CAPE'], dtype='object')\n",
      "Best R-squared on test data: 0.414898\n",
      "RMSE on train set: 3840317.339035\n",
      "RMSE on test set: 4133562.151323\n",
      "STD on test set: 4832140.13\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Latitude', 'Longitude', 'ss_mean', 'TSI', 'tecUHR', 'CAPE'], dtype='object')\n",
      "Best R-squared on test data: 0.500671\n",
      "RMSE on train set: 3689002.589482\n",
      "RMSE on test set: 3957780.699003\n",
      "STD on test set: 4832140.13\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Selected features: Index(['Latitude', 'Longitude', 'ss_mean', 'ss_count', 'TSI', 'tecUHR',\n",
      "       'CAPE'],\n",
      "      dtype='object')\n",
      "Best R-squared on test data: 0.483489\n",
      "RMSE on train set: 3809455.209698\n",
      "RMSE on test set: 3969362.618642\n",
      "STD on test set: 4832140.13\n",
      "--------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#feature selection with xvalidation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Load the data into a Pandas dataframe\n",
    "df = pd.read_csv('../relevant csvs/Frequency for correlation.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "# Define the target variable and the features you want to use for prediction\n",
    "target = 'Power (J)_sum'\n",
    "all_features = ['Latitude', 'Longitude',\n",
    "            \"ss_mean\", \"ss_count\", \"TSI\", 'tecUHR','CAPE']\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "# Create a KFold cross-validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=77)\n",
    "\n",
    "for i in range(1, 8):\n",
    "    # Create a XGBoost regressor model\n",
    "    model = XGBRegressor(n_estimators=20)\n",
    "\n",
    "    # Use RFE for feature selection\n",
    "    rfe = RFE(model, n_features_to_select=i)\n",
    "\n",
    "    # Keep track of the performance metrics for each fold\n",
    "    r2_scores = []\n",
    "    rmse_train_scores = []\n",
    "    rmse_test_scores = []\n",
    "\n",
    "    # Iterate over the folds and train/evaluate the model\n",
    "    for train_idx, test_idx in kfold.split(df[all_features]):\n",
    "        # Split the data into training and test sets for the current fold\n",
    "        X_train, X_test = df.iloc[train_idx][all_features], df.iloc[test_idx][all_features]\n",
    "        y_train, y_test = np.log(df.iloc[train_idx][target]), np.log(df.iloc[test_idx][target])\n",
    "\n",
    "        # Fit the RFE model to the training data and select the features\n",
    "        rfe.fit(X_train, y_train)\n",
    "        selected_features = X_train.columns[rfe.support_]\n",
    "\n",
    "        # Fit the XGBoost model to the selected features\n",
    "        model.fit(X_train[selected_features], y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = model.predict(X_test[selected_features])\n",
    "\n",
    "        # Evaluate the model's performance using R-squared metric\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "        # Compute RMSE on the train and test data for the current fold\n",
    "        y_pred_train = model.predict(X_train[selected_features])\n",
    "        rmse_train = np.sqrt(mean_squared_error(np.exp(y_train), np.exp(y_pred_train)))\n",
    "        rmse_train_scores.append(rmse_train)\n",
    "\n",
    "        rmse_test = np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred)))\n",
    "        rmse_test_scores.append(rmse_test)\n",
    "\n",
    "    # Compute the mean and standard deviation of the performance metrics over all folds\n",
    "    mean_r2 = np.mean(r2_scores)\n",
    "    mean_rmse_train = np.mean(rmse_train_scores)\n",
    "    mean_rmse_test = np.mean(rmse_test_scores)\n",
    "    std_rmse_test = np.std(rmse_test_scores)\n",
    "    std_y_test = np.exp(y_test).std()\n",
    "\n",
    "\n",
    "    # Print the results for the current value of i\n",
    "    print(\"Selected features: {}\".format(selected_features))\n",
    "    print(\"Best R-squared on test data: {:.6f}\".format(r2))\n",
    "    print(\"RMSE on train set: {:.6f}\".format(rmse_train))\n",
    "    print(\"RMSE on test set: {:.6f}\".format(rmse_test))\n",
    "    print(\"STD on test set: {:.2f}\".format(std_y_test))\n",
    "    print(\"--------------------------------------------------------------------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
